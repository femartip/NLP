{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNMzLr2jhqdu"
      },
      "source": [
        "\n",
        "# Lab session 4: Transformer models\n",
        "\n",
        "\n",
        "This lab covers sequence to sequence modeling with Transformer models.  It was designed to give you some first practical experience with Transformers, and we have limited the required amount of input, in order to keep the time and effort for this lab within limits.\n",
        "\n",
        "General instructions:\n",
        "- Complete the code where needed\n",
        "- Provide answers to questions only in the cell where indicated\n",
        "- **Do not alter the evaluation cells** (`## evaluation`) in any way as they are needed for the partly automated evaluation process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH4Dyj82dESf"
      },
      "source": [
        "# **Section 1: Introduction to HuggingFace and Basic Usage of Transformers**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJJU4-hxfy-f"
      },
      "source": [
        "We will use Transformer neural networks and explore their capabilities on some popular NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB6tDuoKuk5Q"
      },
      "source": [
        "## Huggingface\n",
        "For this lab session, we’ll use [Huggingface's](https://huggingface.co/) library to build a encoder-decoder architecuture. Huggingface provides a quick way to use pre-trained and transformers-based NLP models. [BERT](https://huggingface.co/transformers/model_doc/bert.html), [T5](https://huggingface.co/transformers/model_doc/t5.html), [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html), [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) and many others are readily available in this library. \n",
        "\n",
        "Install the `transformers` and `sentencepiece` (required for tokenization) libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "On0RNwgQWV4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00820e4-e9a3-457c-cdd7-2d6dfd2556a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95.tar.gz (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.7/508.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4)\n",
            "Building wheels for collected packages: sentencepiece\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentencepiece: filename=sentencepiece-0.1.95-cp310-cp310-linux_x86_64.whl size=1546218 sha256=9f5287d2e7e34bb4497378a25e24078c59b85da1aeca842b102294a3b72a7639\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/a4/01/5a500fc0c5a38917ef408c245eb40b7ac96f4a30fc6a346a4c\n",
            "Successfully built sentencepiece\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 sentencepiece-0.1.95 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==\"4.28.1\" sentencepiece==\"0.1.95\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVH8HszOTlIj"
      },
      "source": [
        "### Usage\n",
        "HuggingFace's Transformers library is built around three types of classes for each pretrained model:\n",
        "\n",
        "* **model** classes, e.g., `BertModel` which inherits `torch.nn.Modules` and handles loading pretrained weights.\n",
        "\n",
        "* **configuration** classes which store all the parameters required to build a model, e.g., `BertConfig`. You don’t always need to instantiate these yourself. In particular, if you are using a pretrained model without any modification, creating the model will automatically take care of instantiating the configuration (which is part of the model).\n",
        "\n",
        "* **tokenizer** classes which store the vocabulary for each model and provide methods for encoding (and decoding) strings into a list of token embedding indices to be fed to a model, e.g., `BertTokenizer`.\n",
        "\n",
        "All these classes can be instantiated from pretrained instances and saved locally using two methods: \n",
        "\n",
        "1. `from_pretrained()` lets you instantiate a model/configuration/tokenizer from a pretrained version either provided by the library itself or stored locally.\n",
        "\n",
        "2. `save_pretrained()` lets you save a model/configuration/tokenizer locally so that it can be reloaded using `from_pretrained()`.\n",
        "\n",
        "\n",
        "For example you can load a pretrained model/config/tokenizer with:\n",
        "\n",
        "  ```\n",
        "  # import library\n",
        "  from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "  # load config\n",
        "  configuration = BertConfig.from_pretrained('bert-base-uncased')\n",
        "  \n",
        "  # load tokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  \n",
        "  # load model\n",
        "  model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "  # or \n",
        "  model = BertModel.from_pretrianed(configuration)\n",
        "  ```\n",
        "\n",
        "Note that in this session we will focus on using and finetuning a pretrained model, not the (pre)training itself. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnxXjt1Lesv8"
      },
      "source": [
        "### Question-1\n",
        "\n",
        "- What's the difference between pretraining and finetuning?   \n",
        "\n",
        "In finetuning, you use a model that is all ready trained, if the task you are doing is different from the one the model has been trained on, you cut the head of the model and add one that feets you task, then you \"finetune\" the model by freezing all the weights except a little percentage of the weights, which will be trained in your task, it is important to use a low learning rate and low number of epochs, as with this method, it is likely that the model overfitts a lot to the task.\n",
        "Pretraining, uses the weights of a model that was all ready trained, and trains this model further for your task. This gives an advantage as, instead of randomly initializing the weights and than learning its value, now the model starts with an approximation of how the weights will be, this gives a head start."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q7yfDBuQT0s"
      },
      "source": [
        "We will use a pretrained T5 model to perform some initial experiments. As introduced in the theory lecture, T5 is a transformer based model which uses the encoder-decoder structure. It uses the same basic architecture as proposed in the original transformer paper [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762) with some minor variations. It is based on the core idea that most problems in NLP can be formulated as text to text transformation. In other words, given a sequence of words as input, the\n",
        "model produces another sequence of words as output. The figure below shows how the input and output are formulated for performing a variety of NLP tasks using the T5 model (also see DL lecture 8).\n",
        "\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s640/image3.gif\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBuB_t-FgLOv"
      },
      "source": [
        "Lets see how T5 actually works. As always, we import the necessary modules and initialize with a specific random seed (for reproducibility). Your device should be set to \"cuda\", not \"cpu\". (If not, you can change this in \"Edit\" > \"Notebook settings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7lyeDmLvH6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dbfb90-c75e-4019-f8ee-bd2bce809fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# for reproducibility\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PijHm2EiTAW"
      },
      "source": [
        "## Tokenizer playground\n",
        "\n",
        "To build an encoder-decoder pipeline we should prepare input data. We shall use the `tokenizer` class, which offers a clean way to convert raw text into ids. For this part, we'll ask you to:\n",
        "\n",
        "- load the `T5` tokenizer\n",
        "- tokenize the given sentence into subwords (e.g., `*love NLP*` will convert to `['▁love', '▁N', 'LP']` according to the pretrained tokenizer)\n",
        "- encode and then decode the given sentence  \n",
        "\n",
        "**Note**: You might get the following warning: \"FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5\". Feel free to ignore it.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1CmEj7FoRbN5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "66842705b10545f78ad9a60ec90ade56",
            "5f0b65c239ec4e1482a4cf0e6a026b15",
            "7d86ce93ec314c4791c62909809a1989",
            "069e85ffbd734aa39090084116171517",
            "68bfd3c452f74f11838a2a2339281d1a",
            "8baf202746624c118986a31cdd943350",
            "1fe4ef25fafe4b2288896b5c84dd3e72",
            "8c51f944ae674b498a29fce38ea35cb3",
            "0d46cab9f02e42bbbc5b62954d081984",
            "ee24497771814693ad887fdb69da930a",
            "7b5bc7627d1e4489bbc998fca55deb33",
            "1b161767a1ae43ce968f29179dae2fa8",
            "2aa70a336cd345bdbcab2cc126ca86fd",
            "627d2a3b2364424f8dc992f0f1348962",
            "05e689d8c4a146428780d23a353c6248",
            "7cb920c2e0c14a5582ba51734737aa3f",
            "fb259e7cd20d4a3890b1ec82c8f777b2",
            "1aa6068b45df451285c28a083c812601",
            "3061706cc1db4b73887e990f672e8d72",
            "d9ef3405d3de48e6af2a9b3ca8f17fed",
            "8043e9b9694a40b5941745a879f44ef2",
            "211babb11e0b4c72a81956618b0d9f64"
          ]
        },
        "outputId": "47ed7115-baa3-477d-e309-56c65ba69743"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66842705b10545f78ad9a60ec90ade56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b161767a1ae43ce968f29179dae2fa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁Don', \"'\", 't', '▁you', '▁love', '▁the', '▁N', 'LP', '▁course', '?', '▁We', '▁sure', '▁do', '.']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'input_ids': tensor([[1008,   31,   17,   25,  333,    8,  445, 6892,  503,   58,  101,  417,\n",
            "          103,    5,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Don't you love the\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "dummy_sentence = \"Don't you love the NLP course? We sure do.\"\n",
        "\n",
        "# 1) load t5 tokenizer (with `T5Tokenizer.from_pretrained', based on the \"t5-base\")\n",
        "\n",
        "# 2) tokenize dummy_sentence into subwords (use `tokenizer.tokenize')\n",
        "# dummy_tokens = ...\n",
        "\n",
        "# 3) encode dummy_sentence into a pytorch tensor (use `tokenizer.encode_plus' with the argument return_tensors='pt', \n",
        "# to return torch.Tensor objects). You can also just `__call__` the tokenizer.\n",
        "# dummy_tensor = ...\n",
        "\n",
        "# 4) decode the first 6 input_ids [0,6) from the encoded input again (use `tokenizer.decode')\n",
        "# dummy_decode = ...\n",
        "\n",
        "############### for student ################\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "dummy_tokens = tokenizer.tokenize(dummy_sentence)\n",
        "\n",
        "dummy_tensor = tokenizer.encode_plus(dummy_tokens, return_tensors='pt')\n",
        "\n",
        "dummy_decode = tokenizer.decode(dummy_tensor.input_ids[0][0:6])\n",
        "############################################\n",
        "\n",
        "print(dummy_tokens)\n",
        "print('-' * 100)\n",
        "print(dummy_tensor)\n",
        "print('-' * 100)\n",
        "print(dummy_decode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i-78ALsAtyQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e80d83-8521-47e3-ce3e-365cee68c3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done!\n"
          ]
        }
      ],
      "source": [
        "## evaluation\n",
        "## DON'T CHANGE THIS CELL IN ANY WAY\n",
        "\n",
        "assert tokenizer is not None\n",
        "assert tokenizer.name_or_path.find('t5')!=-1, \"load t5 tokenizer\"\n",
        "assert len(tokenizer) == 32100, \"load base tokenizer\"\n",
        "assert len(dummy_tokens) == 14\n",
        "assert dummy_tokens[4] == '▁love'\n",
        "assert isinstance(dummy_tensor, transformers.tokenization_utils_base.BatchEncoding), 'use encode_plus!'\n",
        "assert dummy_decode == \"Don't you love the\"\n",
        "\n",
        "del dummy_tokens\n",
        "del dummy_decode\n",
        "del dummy_tensor\n",
        "\n",
        "print('Well done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FC3qi_CeZkIa"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import T5EncoderModel\n",
        "\n",
        "class BinaryClassifierWithT5(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # We only load encoder part\n",
        "        # (ignore the warning message)\n",
        "        self.t5_model = T5EncoderModel.from_pretrained('t5-base')\n",
        "        \n",
        "        # 1) Get the output dimension of the T5-base model. Huggingface refers \n",
        "        #    to this dimension as `d_model`. You can either look up its value\n",
        "        #    online (https://huggingface.co/t5-base/blob/main/config.json), \n",
        "        #    or get it via `self.t5_model.config.d_model`.\n",
        "        # t5_output_dim = ...\n",
        "\n",
        "        # 2) Create the linear layer with input dimension = t5_output_dim and a scalar output\n",
        "        # self.classifier_head = ... (use a linear layer: `nn.Linear`)\n",
        "        ############### for student ################\n",
        "        t5_output_dim = self.t5_model.config.d_model\n",
        "\n",
        "        self.classifier_head = nn.Linear(t5_output_dim, 1)\n",
        "        ############################################\n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "        # The T5 model outputs a sequence of vectors of size `t5_output_dim`\n",
        "        # (one vector for each token). The dimensions of this tensor are:\n",
        "        # <batch_size, sequence length, t5_output_dim>.\n",
        "        sequence_output = self.t5_model(input_ids, attention_mask)['last_hidden_state']\n",
        "\n",
        "        # 1) To end up with one vector for each sentence in the batch,\n",
        "        #    we want to average the embeddings over all tokens.\n",
        "        # averaged_sequence_output = ...  (use `torch.mean`)\n",
        "\n",
        "        # 2) Pass the averaged sentence embeddings through the linear layer\n",
        "        # lm_logits = ...  (use `self.classifier_head(...)`)\n",
        "        \n",
        "        ############### for student ################\n",
        "        averaged_sequence_output = torch.mean(sequence_output, dim=1)\n",
        "\n",
        "        lm_logits = self.classifier_head(averaged_sequence_output)\n",
        "        ############################################\n",
        "\n",
        "        return lm_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bGaZ7Yfuy3Lz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "f0771bf61d4e4881960670c82c32385c",
            "4b940d7a2e7041289ec1565335992a27",
            "28565eae5daa45628fe5ebe1d2b478c8",
            "9e125ebfa8ad4b0d9d0e69303ae71076",
            "d5be56643e264a80976ea3de571490ff",
            "b4b1ddd78bd04447a75ea3288abcbf5c",
            "04e278470fc34c65808e1cdd08816528",
            "f06e47fb615e4a349a95982a5d56ecd4",
            "5c335db65d724bc7898c5a5492ea96d4",
            "9b5ae09dad72464382c98ab3e878c396",
            "7074c86a0c914ddeb930d52749b139dd"
          ]
        },
        "outputId": "e365fc11-bab2-4611-ad0a-e2f1a436d1e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0771bf61d4e4881960670c82c32385c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight']\n",
            "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done!\n"
          ]
        }
      ],
      "source": [
        "## evaluation\n",
        "## DON'T CHANGE THIS CELL IN ANY WAY\n",
        "\n",
        "dummy_model = BinaryClassifierWithT5()\n",
        "\n",
        "dummy_inps = tokenizer.encode_plus(\"This is a simple example\", return_tensors='pt')\n",
        "\n",
        "dummy_output = dummy_model(input_ids=dummy_inps['input_ids'], attention_mask=dummy_inps['attention_mask'])\n",
        "\n",
        "assert isinstance(dummy_model.classifier_head, nn.Linear) \n",
        "assert dummy_model.classifier_head.out_features == 1, 'Is it binary?'\n",
        "\n",
        "\n",
        "del dummy_model\n",
        "del dummy_inps\n",
        "del dummy_output\n",
        "\n",
        "print('Well done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jydRRk4xbaU"
      },
      "source": [
        "## Prompt or task specification\n",
        "\n",
        "Before jumping into the main part of this lab, we should be familar with Prompt. The technique of prompt or task specification is a way to steer the generation of pretrained language models to solve a (natural language) query of your choice. For example, [T. Brown et al.](https://arxiv.org/pdf/2005.14165.pdf) used prompting for grammar correction (the task of correcting different kinds of errors in text such as spelling, punctuation). They gave prompts of the form \"`Poor English Input: <inp_sentence>\\n Good English Output: <out_sentence>\"`:\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/ezfh1p891h7qes6/Screenshot%20from%202021-05-01%2009-40-00%20%28edited-Pixlr%29.png?raw=1\">\n",
        "\n",
        "\n",
        "In this scenario, the encoder recieves a sentence in the form of \"`Poor English Input: <inp_sentence>\\n` and the decoder predicts the `Good English Output: <out_sentence>` with `<x_sentence>` an example in our dataset. \n",
        "\n",
        "\n",
        "T5 has some built-in prompts such as:\n",
        "\n",
        "- translate English to French: `YOUR_INPUT_SENTENCE`\n",
        "- translate English to German: `YOUR_INPUT_SENTENCE`\n",
        "- cola sentence: `YOUR_INPUT_SENTENCE`\n",
        "- ...\n",
        "\n",
        "Let's see how we can use the T5 model to translate \"`I am a student`\" into French and German using prompts in combination with a pretrained language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LpiSZeCG42wH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "20b8bd07a5f64a7ea893e613357d5b09",
            "8e544e4e0ce24175aff5f8b1448de0ca",
            "97276fc19a9b46cfbfa4e1795324f4e3",
            "ee34145d4cc947059e999f51c716ce38",
            "3b911f20ffca4d65ba51617c4ef669bf",
            "d455b06b4d424f179ad9fa5c855591c1",
            "bcb49f311fe64267b5d1e476282a2ffb",
            "70abf94ffedf4570b43807bdcd8cee17",
            "00e1419afa8f48da9a324f1ad63f5b8c",
            "71d077f93d68495ca65d02304e94b845",
            "cc791fb65e394502bbde9b47e0042512"
          ]
        },
        "outputId": "5b827e8e-c9fe-4219-e0d3-0b64563e15fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20b8bd07a5f64a7ea893e613357d5b09"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# load t5 model\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x8swr60OsYYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6dd043-8832-495a-a6e6-5314ca0b1c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Je suis un étudiant', 'Ich bin Studentin']\n"
          ]
        }
      ],
      "source": [
        "examples = [\n",
        " \"translate English to French: I am a student\", \n",
        " \"translate English to German: I am a student\",         \n",
        "]\n",
        "\n",
        "translation_list = []\n",
        "\n",
        "# for each example:\n",
        "# 1. encode your inputs and return a tensor with `tokenizer.encode`\n",
        "# 2. pass the encoded input through the T5 model with the `generate` function\n",
        "# 3. decode the generated output with the tokenizer (convert ids to tokens) with `tokenizer.decode`.\n",
        "#    make sure to retain only the translation itself, not the special tokens such as padding\n",
        "# 4. append this decoded output to the translation_list\n",
        "\n",
        "for e in examples:\n",
        "    ############### for student ################\n",
        "    encode_e = tokenizer.encode(e,return_tensors='pt')\n",
        "    #print(encode_e)\n",
        "    encode_model = t5_model.generate(encode_e)\n",
        "    #print(encode_model)\n",
        "    decoded_e = tokenizer.decode(encode_model[0] ,clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
        "    #print(decoded_e.split)\n",
        "    translation_list.append(decoded_e)\n",
        "    ############################################\n",
        "print(translation_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "beVNPdPspQ9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753fa30d-3ad9-42cf-cda1-5d0cd014c99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done!\n"
          ]
        }
      ],
      "source": [
        "## evaluation\n",
        "## DON'T CHANGE THIS CELL IN ANY WAY\n",
        "assert len(translation_list) == 2, \"decode both examples?\"\n",
        "assert translation_list[0] == \"Je suis un étudiant\"\n",
        "assert translation_list[1] == \"Ich bin Studentin\"\n",
        "\n",
        "print('Well done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1paas2u_y_Kk"
      },
      "source": [
        "# **Section 2: Fine-tuning pretrained DistilBERT for classification**\n",
        "\n",
        "\n",
        "In this experiment we'll fine-tune a pretrained DistilBERT model for a classification task. \n",
        "DistilBERT is a small, fast, cheap and light Transformer model based on the BERT architecture. Knowledge distillation is performed during the pre-training phase to reduce the size of the original BERT model by 40%. Here's an interesting [blog](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f) behind the approach of DistilBERT and knowledge distillation in BERT-like models in general. \n",
        "\n",
        "We use a twitter dataset of complaints of airline customers to build our classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K09zV32rpzQT"
      },
      "source": [
        "### Question-2\n",
        "\n",
        "- What's the difference between finetuning and freezing transformers?   \n",
        "\n",
        "Fine-tuning and freezing are two techniques that can be used when adapting a pre-trained transformer model to a new task. Fine-tuning involves training the model on new data specific to your task. During fine-tuning, you can choose to update all the weights of the model or only a subset of them. In the latter case, the layers that are not being fine-tuned are “frozen”. On the other hand, freezing refers to the process of preventing the weights of a model from being updated during training. When you freeze all the weights of a model, you are essentially using it as a fixed feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OWmZLgLRphz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80279ae7-8744-45e7-e589-2d3cccfd2fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import torch\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h-vIfA96t9Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483fcb6a-345e-41c7-9912-6d62de9b9f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.95)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Sentencepiece\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1js4xubKsca_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2f73c758-9109-48a7-9af4-76a92c8fc2e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                              tweet  label\n",
              "291    95181  @JLJeffLewis @AmericanAir no excuse for lost l...      0\n",
              "755    20845  I thought airport wi-fi was ridiculous until I...      0\n",
              "2096   32473  @DanniAllen14 @united @RunLikeAGirl_ca @just_t...      1\n",
              "432   165082  My @united flight to LA had no electricity for...      0\n",
              "479    37552  Poop. _@stevethebikeguy: @JetBlue announces ne...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16df9ce0-dd54-4fe9-b909-3bf8c24a5878\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>95181</td>\n",
              "      <td>@JLJeffLewis @AmericanAir no excuse for lost l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>20845</td>\n",
              "      <td>I thought airport wi-fi was ridiculous until I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2096</th>\n",
              "      <td>32473</td>\n",
              "      <td>@DanniAllen14 @united @RunLikeAGirl_ca @just_t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>165082</td>\n",
              "      <td>My @united flight to LA had no electricity for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>37552</td>\n",
              "      <td>Poop. _@stevethebikeguy: @JetBlue announces ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16df9ce0-dd54-4fe9-b909-3bf8c24a5878')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16df9ce0-dd54-4fe9-b909-3bf8c24a5878 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16df9ce0-dd54-4fe9-b909-3bf8c24a5878');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "complaint_train = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/twitter_train.csv\", encoding='latin-1')\n",
        "complaint_test = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/twitter_test.csv\", encoding='latin-1')\n",
        "\n",
        "complaint_train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gZDYQN9KqnMT"
      },
      "outputs": [],
      "source": [
        "X = complaint_train.tweet.values\n",
        "y = complaint_train.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mHP3-vfYqtxt"
      },
      "outputs": [],
      "source": [
        "def preprocess_tweet(text):\n",
        "  \n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)    # Remove '@name'\n",
        "    text = re.sub(r'&amp;', '&', text)  # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove trailing whitespace\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ni_obYQ2RDo"
      },
      "source": [
        "First, we need to tokenize the input text into token IDs, before it can be fed into DistilBERT. The figure below illustrates the tokenization process.\n",
        "\n",
        "\n",
        "\n",
        "![img](http://jalammar.github.io/images/distilBERT/bert-distilbert-input-tokenization.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-AxSe0P_q08z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f47e90254bfb4fcf99b616b104deaa25",
            "93b10ec0d7634a8eaacaa638e4f0fea6",
            "db649c782dba4cb09dadfccf6e42c183",
            "0ce253b7c74845e5b0129d9ea35d9633",
            "60ae4e20f442483e92c7e5ddf6184641",
            "55c33b30398c417a9b6d3556818c8f86",
            "eb548d5ef38640c88113972a75d51c78",
            "3337eb94450049a4bf1ace6c3f3f3f7e",
            "4b066a0c084b4ad8aee40b379495a512",
            "91419961eb72467190db3f84fcb8c912",
            "e5507ebaa5c24b8fad28650954d4b45d",
            "4b85d78813084afe9c0ffbd2c0fb986d",
            "cd02ab6c30d940bb94b9fe1234347a22",
            "47fa5bbf8b4f4544990ec69309d3ca4f",
            "f837c095d11f4533bcae98a7590084f6",
            "6990f45e177444f683f763c25dc66fdf",
            "a924ff5ee6ff4af0b331dffe41f5ecdd",
            "71a5c3e333604e59a5876a9365aed934",
            "fa2652dbcfda4340b7aaa307907690f9",
            "ff9cc159c6014b08940752c291cec3af",
            "f2265560be374c5b80bc01e134eec872",
            "d4a0b97f2cb24e67b9d7eaaac71da6d6",
            "42247fa19bdd4b7ebb426206f3ef9fb2",
            "49f4c35634144433a4298ddce2a42cfa",
            "d0f97553ff2f44bea4ffde20151dfff2",
            "aeadf58529e546ebb7c7493ffb056205",
            "a5c619a73bfd4418b68caa31d8fda16a",
            "5bbf0d2448874e12badb5d48f5d6a22a",
            "c5a90a4f339d4bc5bcecfbdbf54a87c1",
            "afa1431f51d84130816cfa01ef985f31",
            "18b752e6446a4e19b70670d9c479799b",
            "c1934ed6e37a418f99fd30be92356927",
            "5799a1407eb24dd0a9e5079720f61763"
          ]
        },
        "outputId": "bd081e10-83eb-4be0-aac9-9d11986ce0e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f47e90254bfb4fcf99b616b104deaa25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b85d78813084afe9c0ffbd2c0fb986d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42247fa19bdd4b7ebb426206f3ef9fb2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "# Load the Distilled BERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained DistilBERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in data:\n",
        "        # `tokenizer` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Return an attention mask\n",
        "        #    (6) Return a dictionary of tokens mapped to IDs\n",
        "        \n",
        "\n",
        "        encoded_sent = tokenizer(\n",
        "            text=preprocess_tweet(sent),           # Preprocess the tweet\n",
        "            add_special_tokens=True,               # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                    # Max length to truncate/pad\n",
        "            padding='max_length',                  #Pad each sequence to the max_length argument provided        \n",
        "            truncation =True,                      #Truncate each sequence to the max_length argument provided\n",
        "            return_attention_mask = True\n",
        "            )\n",
        "\n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        \n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    \n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v4_OJWhiq_rL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ae6af4-09db-483c-dc42-016adf03031b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data...\n"
          ]
        }
      ],
      "source": [
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDLCutcRrPyN"
      },
      "source": [
        "Now, we will create a Pytorch DataLoader. This allows us to easily load in batches of our new tokenized dataset during the training and validation process. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pBNQH2Wwq_w_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z10ZEcWerZVg"
      },
      "source": [
        "Next, we need to define the architecture of our classifier, which is built upon DistilBert. Please follow the instructions in the code below to add a feed-forward classifier after the pre-trained BERT model. You are also instructed to freeze the parameters in the pre-trained BERT model we have loaded from the transformer class. This ensures that only the newly defined classification layer is trained, while the parameters of the pre-trained BERT model are kept constant. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "voYvcSB7rdJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91805e0-aea1-438c-9310-85c58b112a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 44 µs, sys: 10 µs, total: 54 µs\n",
            "Wall time: 58.7 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from transformers import BertModel, DistilBertModel\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "\n",
        "# Create the DistilBertClassfier class\n",
        "class DistilBertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, unfreeze_layers=None):\n",
        "        super(DistilBertClassifier, self).__init__()\n",
        "\n",
        "\n",
        "        D_in, H, D_out = 768, 50, 2          # Specify hidden size of DistilBERT, hidden size of our classifier, and number of labels\n",
        "\n",
        "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")    # Load DistilBERT model\n",
        "        \n",
        "        # Instantiate a one-layer feed-forward classifier\n",
        "        # this classifier consists of a single hidden layer, with nn.RELU() between the hidden and output layer\n",
        "        # self.classifier = nn.Sequential ( ... )\n",
        "            \n",
        "        ############### for student ################\n",
        "        self.classifier = nn.Sequential(nn.Linear(D_in, H),nn.ReLU(), nn.Linear(H, D_out))\n",
        "\n",
        "        ############################################\n",
        "\n",
        "        # Freeze all the trainable layers in the DistilBertModel\n",
        "        # (1) loop through all the parameters in self.bert (you should look up how to access the parameters of a layer/model in PyTorch)\n",
        "        # (2) for each parameter, set requires_grad to False \n",
        "\n",
        "        ############### for student ################\n",
        "        for param in self.bert.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        ############################################\n",
        "\n",
        "        # unfreeze/train the specific layers of the transformer \n",
        "        if unfreeze_layers is not None:\n",
        "            assert isinstance(unfreeze_layers, list), \"unfreeze_layers expects a list of layers to unfreeze\"\n",
        "          \n",
        "            for layer_no in unfreeze_layers:\n",
        "                for param in list(self.bert.transformer.layer[layer_no].parameters()):\n",
        "                    param.requires_grad = True\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \n",
        "        outputs = self.bert(input_ids=input_ids,            # input_ids.shape = attention_mask.shape (batch_size, max_length)\n",
        "                            attention_mask=attention_mask)\n",
        "             \n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]         # Extract the last hidden state of the token `[CLS]` as an input for the classification task    \n",
        "        logits = self.classifier(last_hidden_state_cls)     #logits.shape (batch_size, num_labels)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1jZSkH8r_i7"
      },
      "source": [
        "We have implemented the training loop for you. Please study the code in the trainer class so you understand what is going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "56SOdsy0sB9i"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import torch.nn as nn\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def mytrainer(model, optimizer, train_dataloader,  val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the  model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "   \n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "        \n",
        "        model.train()   # Put the model into the training mode\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            \n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)  # Load batch to GPU            \n",
        "            model.zero_grad()    # Zero out any previously calculated gradients\n",
        "            logits = model(b_input_ids, b_attn_mask)  # Perform a forward pass. \n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()    # Perform a backward pass to calculate gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)    # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        " \n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # Measure model's performance on the validation set after each epoch\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"Eval {epoch_i + 1:^2} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance on the validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3bbxmIUpsLaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f819e9b203c945e185dfbf976659542c",
            "705b1c4a28434000be5e11f1a3dd152f",
            "fec04461235c4f28843ba8a48c67c620",
            "acabaeded6024ec0bfa3fb2870fa5d2e",
            "b420e1ee320148908ed7f3bbfbe2615c",
            "a46e59d027064baaab21d491c165bafb",
            "3cf547bbe7284b3c99ab9c6dc42f65b9",
            "fef1e8b057764a30b2d501d188bc1e64",
            "52c251ecc9a84c619cbe6ac0287a874a",
            "ac022fc8d4364427aac6c513f4b171b0",
            "c7cceb6e830f46c38c5db4758808e71b"
          ]
        },
        "outputId": "a141cbac-d0cb-47b2-ac3b-dc3b78efc1bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f819e9b203c945e185dfbf976659542c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.695247   |     -      |     -     |   5.49   \n",
            "   1    |   40    |   0.691375   |     -      |     -     |   1.12   \n",
            "   1    |   60    |   0.686200   |     -      |     -     |   1.11   \n",
            "   1    |   80    |   0.683507   |     -      |     -     |   1.09   \n",
            "   1    |   95    |   0.680904   |     -      |     -     |   0.79   \n",
            "----------------------------------------------------------------------\n",
            "Eval 1  |    -    |   0.687869   |  0.676163  |   64.26   |   10.14  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.675791   |     -      |     -     |   1.14   \n",
            "   2    |   40    |   0.670133   |     -      |     -     |   1.06   \n",
            "   2    |   60    |   0.666528   |     -      |     -     |   1.13   \n",
            "   2    |   80    |   0.659118   |     -      |     -     |   1.09   \n",
            "   2    |   95    |   0.662668   |     -      |     -     |   0.84   \n",
            "----------------------------------------------------------------------\n",
            "Eval 2  |    -    |   0.667158   |  0.655508  |   61.59   |   5.81   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.661318   |     -      |     -     |   1.20   \n",
            "   3    |   40    |   0.657538   |     -      |     -     |   1.15   \n",
            "   3    |   60    |   0.649730   |     -      |     -     |   1.15   \n",
            "   3    |   80    |   0.642951   |     -      |     -     |   1.14   \n",
            "   3    |   95    |   0.652480   |     -      |     -     |   0.85   \n",
            "----------------------------------------------------------------------\n",
            "Eval 3  |    -    |   0.652909   |  0.636445  |   65.06   |   6.06   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.640496   |     -      |     -     |   1.26   \n",
            "   4    |   40    |   0.634954   |     -      |     -     |   1.19   \n",
            "   4    |   60    |   0.633114   |     -      |     -     |   1.17   \n",
            "   4    |   80    |   0.642148   |     -      |     -     |   1.06   \n",
            "   4    |   95    |   0.636438   |     -      |     -     |   0.78   \n",
            "----------------------------------------------------------------------\n",
            "Eval 4  |    -    |   0.637513   |  0.621772  |   68.01   |   6.01   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.628824   |     -      |     -     |   1.12   \n",
            "   5    |   40    |   0.622055   |     -      |     -     |   1.06   \n",
            "   5    |   60    |   0.614926   |     -      |     -     |   1.06   \n",
            "   5    |   80    |   0.621024   |     -      |     -     |   1.08   \n",
            "   5    |   95    |   0.634897   |     -      |     -     |   0.79   \n",
            "----------------------------------------------------------------------\n",
            "Eval 5  |    -    |   0.623842   |  0.612387  |   70.00   |   5.67   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   0.627740   |     -      |     -     |   1.14   \n",
            "   6    |   40    |   0.625170   |     -      |     -     |   1.07   \n",
            "   6    |   60    |   0.604188   |     -      |     -     |   1.07   \n",
            "   6    |   80    |   0.610604   |     -      |     -     |   1.07   \n",
            "   6    |   95    |   0.602385   |     -      |     -     |   0.80   \n",
            "----------------------------------------------------------------------\n",
            "Eval 6  |    -    |   0.614766   |  0.599370  |   70.68   |   5.71   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   0.608779   |     -      |     -     |   1.12   \n",
            "   7    |   40    |   0.610279   |     -      |     -     |   1.09   \n",
            "   7    |   60    |   0.605090   |     -      |     -     |   1.09   \n",
            "   7    |   80    |   0.597924   |     -      |     -     |   1.08   \n",
            "   7    |   95    |   0.588735   |     -      |     -     |   0.80   \n",
            "----------------------------------------------------------------------\n",
            "Eval 7  |    -    |   0.602930   |  0.592701  |   70.00   |   5.75   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   0.605333   |     -      |     -     |   1.15   \n",
            "   8    |   40    |   0.596652   |     -      |     -     |   1.10   \n",
            "   8    |   60    |   0.594793   |     -      |     -     |   1.10   \n",
            "   8    |   80    |   0.582538   |     -      |     -     |   1.09   \n",
            "   8    |   95    |   0.591255   |     -      |     -     |   0.80   \n",
            "----------------------------------------------------------------------\n",
            "Eval 8  |    -    |   0.594380   |  0.577263  |   71.65   |   5.81   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "set_seed(42)    # Set seed for reproducibility\n",
        "\n",
        "bert_classifier = DistilBertClassifier()\n",
        "bert_classifier.to(device)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = torch.optim.AdamW(bert_classifier.parameters(),\n",
        "                  lr=5e-5,    # Default learning rate\n",
        "                  eps=1e-8    # Default epsilon value\n",
        "                  )\n",
        "\n",
        "mytrainer(bert_classifier, optimizer, train_dataloader, val_dataloader, epochs=8, evaluation=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47ITYNLwJhb"
      },
      "source": [
        "We will now fine-tune the DistilBert model by unfreezing specific layers in the pre-trained model, and training our full model (encoder + classifier) again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1Bv-hVz2wVyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271edc84-c970-4a90-fafa-a941795d267f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.651182   |     -      |     -     |   1.45   \n",
            "   1    |   40    |   0.558613   |     -      |     -     |   1.39   \n",
            "   1    |   60    |   0.565137   |     -      |     -     |   1.39   \n",
            "   1    |   80    |   0.498318   |     -      |     -     |   1.38   \n",
            "   1    |   95    |   0.539594   |     -      |     -     |   1.02   \n",
            "----------------------------------------------------------------------\n",
            "Eval 1  |    -    |   0.564689   |  0.479649  |   77.33   |   7.19   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.447765   |     -      |     -     |   1.48   \n",
            "   2    |   40    |   0.453068   |     -      |     -     |   1.41   \n",
            "   2    |   60    |   0.457475   |     -      |     -     |   1.40   \n",
            "   2    |   80    |   0.509824   |     -      |     -     |   1.40   \n",
            "   2    |   95    |   0.483136   |     -      |     -     |   1.03   \n",
            "----------------------------------------------------------------------\n",
            "Eval 2  |    -    |   0.469349   |  0.513102  |   78.86   |   7.28   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.454012   |     -      |     -     |   1.48   \n",
            "   3    |   40    |   0.470403   |     -      |     -     |   1.40   \n",
            "   3    |   60    |   0.421183   |     -      |     -     |   1.40   \n",
            "   3    |   80    |   0.425613   |     -      |     -     |   1.41   \n",
            "   3    |   95    |   0.491902   |     -      |     -     |   1.04   \n",
            "----------------------------------------------------------------------\n",
            "Eval 3  |    -    |   0.450591   |  0.475766  |   78.58   |   7.31   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.374251   |     -      |     -     |   1.50   \n",
            "   4    |   40    |   0.407707   |     -      |     -     |   1.42   \n",
            "   4    |   60    |   0.393207   |     -      |     -     |   1.41   \n",
            "   4    |   80    |   0.432082   |     -      |     -     |   1.41   \n",
            "   4    |   95    |   0.461337   |     -      |     -     |   1.04   \n",
            "----------------------------------------------------------------------\n",
            "Eval 4  |    -    |   0.410825   |  0.486268  |   77.05   |   7.35   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.423276   |     -      |     -     |   1.49   \n",
            "   5    |   40    |   0.355892   |     -      |     -     |   1.41   \n",
            "   5    |   60    |   0.375783   |     -      |     -     |   1.41   \n",
            "   5    |   80    |   0.355929   |     -      |     -     |   1.42   \n",
            "   5    |   95    |   0.411289   |     -      |     -     |   1.04   \n",
            "----------------------------------------------------------------------\n",
            "Eval 5  |    -    |   0.383440   |  0.488777  |   78.18   |   7.35   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   0.331562   |     -      |     -     |   1.48   \n",
            "   6    |   40    |   0.334631   |     -      |     -     |   1.40   \n",
            "   6    |   60    |   0.339935   |     -      |     -     |   1.40   \n",
            "   6    |   80    |   0.383024   |     -      |     -     |   1.40   \n",
            "   6    |   95    |   0.363425   |     -      |     -     |   1.02   \n",
            "----------------------------------------------------------------------\n",
            "Eval 6  |    -    |   0.349645   |  0.531021  |   79.77   |   7.27   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   0.331382   |     -      |     -     |   1.47   \n",
            "   7    |   40    |   0.339767   |     -      |     -     |   1.39   \n",
            "   7    |   60    |   0.334442   |     -      |     -     |   1.39   \n",
            "   7    |   80    |   0.341417   |     -      |     -     |   1.41   \n",
            "   7    |   95    |   0.356761   |     -      |     -     |   1.04   \n",
            "----------------------------------------------------------------------\n",
            "Eval 7  |    -    |   0.339822   |  0.560980  |   77.33   |   7.27   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   0.315076   |     -      |     -     |   1.47   \n",
            "   8    |   40    |   0.331613   |     -      |     -     |   1.39   \n",
            "   8    |   60    |   0.329569   |     -      |     -     |   1.39   \n",
            "   8    |   80    |   0.304016   |     -      |     -     |   1.39   \n",
            "   8    |   95    |   0.342331   |     -      |     -     |   1.02   \n",
            "----------------------------------------------------------------------\n",
            "Eval 8  |    -    |   0.323495   |  0.569956  |   78.64   |   7.22   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "\n",
        "unfreeze_layers = [5]   # We'll fine-tune the last layer (update the weights of that specific layer) of distilBERT\n",
        "\n",
        "unfrozen_classifier = DistilBertClassifier(unfreeze_layers=unfreeze_layers)\n",
        "\n",
        "unfrozen_classifier.to(device)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = torch.optim.AdamW(unfrozen_classifier.parameters() )\n",
        "mytrainer(unfrozen_classifier, optimizer, train_dataloader, val_dataloader, epochs=8, evaluation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIfxBeMSw98Q"
      },
      "source": [
        "### Question-3\n",
        "\n",
        "- Which classifier (`bert_classifier` or `unfrozen_classifier`) takes more time to train? Which one performs better in terms of validation accuracy? Explain. \n",
        "\n",
        "Comparing times, bert_classifier takes slightly less time than unforzen_classifier (56s vs 60s respectively). However with respect to performance, unforzen_classifier performes way better in the validation set than bert_classifier (78.74% vs 71.65% respectively). This make sence, as the freezed model will have way less parameters to learn (only the ones in the output layer we have added) it will take less time, however it will fit worst to our data. In the contrary, the unfreezed model has more parameters, this means it will take more time to learn but as shown works way better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARkLEiZg3Hht"
      },
      "source": [
        "\n",
        "# **Section 3: Multi-lingual transformers: LaBSE** \n",
        "\n",
        "In this exercise, we'll use yet another pre-trained transformer, namely the `Language agnostic BERT sentence embedding` model [LabSe](https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html). This is a multilingual sentence embedding model that encodes text from different languages into a shared embedding space. This allows it to be applied to a range of downstream tasks, like text classification, clustering, and others, while also leveraging semantic information for language understanding.\n",
        "\n",
        "We will fine-tune the LabSe model for a sentiment classifiction task based on small sample of the [YELP](https://www.yelp.com/dataset) dataset in English. \n",
        "\n",
        "We will then evaluate our fine-tuned model on a test set in another language (DUTCH, FRENCH) and inspect how agnostic our model really is to the language change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dNd7ciTS4ZUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cceb452-39f5-45b2-fcc2-1ff23e7782c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z0zLj2d6An9V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tGfyHy8p75Nr"
      },
      "outputs": [],
      "source": [
        "#Load your data into a dataframe\n",
        "yelp = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/yelp_train.csv\", encoding='latin-1')\n",
        "\n",
        "X = yelp.text.values\n",
        "y = yelp.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gf0Hf_Cihjz"
      },
      "source": [
        "As in the previous exercise, we will first create a preprocessing function that tokenizes the input text and tensorizes it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DMvzKUuF8NMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8343c7815d6d4564b0128beed266448c",
            "90bd4cc455f24d57ba06777fe2cec727",
            "6688338eb9f642eeb7174f949849509d",
            "1dc7eb78e9414353813f1055eccf995b",
            "8e475bf5c0b04c7fb74ac8ec78c6e941",
            "1c2b564592834ff09ff9d937951ace50",
            "4b299bb4368f4dc7b930c74f2fbe4f0d",
            "c940befa33ef4c17a6471b2a8eba318c",
            "7f52cb75ca8b42a496e09deb2891dfee",
            "d011d98003884782ad9e59cde4b01598",
            "a38a109e0c3c4e188c2c97606def975d",
            "0e92413bde84489b97409cbb841cef3c",
            "a4eb2b13d4314c8c94b21a819ac0aa7f",
            "bcf2d4e95fd244e6b6589aa39145e7dc",
            "05eaa32c55bd42c5924a447bdd4f88fd",
            "aba49d548c204333be1022f7a4fdd6a5",
            "cc1aff73f1d242c6b1e7f54128d7227a",
            "833c9530087c43939646129c80a5cdf5",
            "bd79ea5104f74a97b831ab501b58f850",
            "4832d9c702d34e118fb20f0bff64a77a",
            "352fdffd3304402e9a76242a2c7fd898",
            "43f00a8f79b54f0cb3ac3711add45ef4",
            "cae4b4b0fb5942999db3b1e9144d6df9",
            "b9808bd828684cd69a0a5328a2634c03",
            "a2fb7d665f22412e9790247ecc1ecee0",
            "12e1f17dedaf4658bb1a473b2b34447b",
            "a7f9053d095e4c7e8f40e973fab1a3b5",
            "29395c6b54804ecaad630fa1c64ae646",
            "3d188f4ec23743569ffde3291f6353c6",
            "484109424b304376a1062be6a03c42a7",
            "a8b02cd6fd804584a0329721d93b68bd",
            "53eb1c4224b8413f95cea417195271b3",
            "4ca13dd169f241229f11976c593ca1aa",
            "cf08fe5c9cae4ee0859ebebd3e70bd51",
            "55235387620b4757a6fb11ed96409223",
            "c3bdc2253a594b728158f99eb6e050f6",
            "e67475d019b34eb486d8a4d10b727e73",
            "026c2ccc64524cd9a945d0423023ccaf",
            "683c101ae50c4268a7628a18d02bc527",
            "68746dda3a0640e1965616f3d0169842",
            "1c5289d22e214f79bc5eaaa5c43a22ee",
            "efe1cc99d10f4167bfe4afa1ea5cb31c",
            "9fd687f3c2fa4f458942fa647917575d",
            "c495ae7f6dde44cc857dc274d1793624"
          ]
        },
        "outputId": "26cb12b7-8fab-4953-f494-cfc63e7db8e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8343c7815d6d4564b0128beed266448c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e92413bde84489b97409cbb841cef3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cae4b4b0fb5942999db3b1e9144d6df9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf08fe5c9cae4ee0859ebebd3e70bd51"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "MAX_LEN = 64\n",
        "mytokenizer = AutoTokenizer.from_pretrained(\"pvl/labse_bert\", do_lower_case=False)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_labse(data):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sent in data:\n",
        "\n",
        "        encoded_sent = mytokenizer(\n",
        "            text=sent,           \n",
        "            add_special_tokens=True,               \n",
        "            max_length=MAX_LEN,                    \n",
        "            padding='max_length',                        \n",
        "            truncation =True,                       \n",
        "            return_attention_mask = True\n",
        "            )\n",
        "\n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    \n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "s7uCx_lU85Nv"
      },
      "outputs": [],
      "source": [
        "train_inputs, train_masks = preprocessing_for_labse(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_labse(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ql0Xov9AWC"
      },
      "source": [
        "Again, we create dataloader which allows us to easily extract batches for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pejzGEKn86cd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s8bX8jW9jPv"
      },
      "source": [
        "Now, we define the LabSeClassifier model architecture. Once again, we initially opt to freeze all parameters in the pre-trained model. Please complete the code where indicated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "8Qif1boT7VDA"
      },
      "outputs": [],
      "source": [
        "class LabSeClassifier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabSeClassifier, self).__init__()\n",
        "        H, D_out = 768, 2 \n",
        "\n",
        "        self.labse_encoder = AutoModel.from_pretrained(\"pvl/labse_bert\")\n",
        "         \n",
        "        #Freeze all the parameters of the LabSe encoder\n",
        "\n",
        "        ############### for student ################ \n",
        "        for param in self.labse_encoder.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        ############################################\n",
        "\n",
        "        self.linear = torch.nn.Linear(H, D_out)       \n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        output = self.labse_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        ### Mean pool over the hidden representations of each token \n",
        "        ### to get a single vector representation for the whole sentence \n",
        "\n",
        "        token_embeddings = output[0]                                            \n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "        labse_representation = sum_embeddings/sum_mask\n",
        "         \n",
        "        logits = self.linear(labse_representation)\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XjN28Pg9xe9"
      },
      "source": [
        "Since we only defined another model and don't aim to change anything about the training strategy, we can reuse the `mytrainer()` function from section 2 (initially used to train the DistilBERT-based tweet classifier). Below, we train the LabSeClassifier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "on6oljnP9RqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08648a3d-6461-477d-a807-cacff5892f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at pvl/labse_bert were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.718796   |     -      |     -     |   1.24   \n",
            "   1    |   40    |   0.699815   |     -      |     -     |   1.12   \n",
            "   1    |   60    |   0.690503   |     -      |     -     |   1.12   \n",
            "   1    |   80    |   0.688534   |     -      |     -     |   1.12   \n",
            "   1    |   100   |   0.679065   |     -      |     -     |   1.12   \n",
            "   1    |   112   |   0.664355   |     -      |     -     |   0.65   \n",
            "----------------------------------------------------------------------\n",
            "Eval 1  |    -    |   0.692259   |  0.674546  |   58.65   |   7.03   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.655523   |     -      |     -     |   1.18   \n",
            "   2    |   40    |   0.660317   |     -      |     -     |   1.28   \n",
            "   2    |   60    |   0.628787   |     -      |     -     |   1.24   \n",
            "   2    |   80    |   0.616830   |     -      |     -     |   1.16   \n",
            "   2    |   100   |   0.606860   |     -      |     -     |   1.15   \n",
            "   2    |   112   |   0.620553   |     -      |     -     |   0.66   \n",
            "----------------------------------------------------------------------\n",
            "Eval 2  |    -    |   0.632465   |  0.634596  |   67.31   |   7.37   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.607211   |     -      |     -     |   1.20   \n",
            "   3    |   40    |   0.604150   |     -      |     -     |   1.14   \n",
            "   3    |   60    |   0.573442   |     -      |     -     |   1.14   \n",
            "   3    |   80    |   0.582852   |     -      |     -     |   1.14   \n",
            "   3    |   100   |   0.593565   |     -      |     -     |   1.15   \n",
            "   3    |   112   |   0.592974   |     -      |     -     |   0.66   \n",
            "----------------------------------------------------------------------\n",
            "Eval 3  |    -    |   0.592454   |  0.601570  |   70.67   |   7.13   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.556672   |     -      |     -     |   1.21   \n",
            "   4    |   40    |   0.572488   |     -      |     -     |   1.14   \n",
            "   4    |   60    |   0.568191   |     -      |     -     |   1.15   \n",
            "   4    |   80    |   0.544272   |     -      |     -     |   1.17   \n",
            "   4    |   100   |   0.562885   |     -      |     -     |   1.20   \n",
            "   4    |   112   |   0.536736   |     -      |     -     |   0.68   \n",
            "----------------------------------------------------------------------\n",
            "Eval 4  |    -    |   0.558298   |  0.579356  |   71.15   |   7.24   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.541724   |     -      |     -     |   1.20   \n",
            "   5    |   40    |   0.521163   |     -      |     -     |   1.14   \n",
            "   5    |   60    |   0.548879   |     -      |     -     |   1.14   \n",
            "   5    |   80    |   0.543688   |     -      |     -     |   1.15   \n",
            "   5    |   100   |   0.519002   |     -      |     -     |   1.14   \n",
            "   5    |   112   |   0.510875   |     -      |     -     |   0.66   \n",
            "----------------------------------------------------------------------\n",
            "Eval 5  |    -    |   0.532401   |  0.559044  |   74.52   |   7.11   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "set_seed(42)    # Set seed for reproducibility\n",
        "\n",
        "\n",
        "labse_classifier = LabSeClassifier()\n",
        "\n",
        "labse_classifier.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(labse_classifier.parameters(),\n",
        "                  lr=5e-5,    # Default learning rate\n",
        "                  eps=1e-8    # Default epsilon value\n",
        "                  )\n",
        "\n",
        "mytrainer(labse_classifier, optimizer, train_dataloader, val_dataloader, epochs=5, evaluation=True)      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAkv7tnJ-Szq"
      },
      "source": [
        "The `labse_predict` function below takes the trained model as an input, together with a test set of unseen instances, and predicts the sentiment of the examples in the test set. It does this by simply passing the inputs through the trained model, and transforming the obtained logits into a probability distribution of sentiment classes.\n",
        "\n",
        "We also define a function to determine the accuracy of the model's sentiment predictions over the test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cjO3hTE7-j5o"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def labse_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "\n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dy0duOCV-vZ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def accuracy_function(yelp_test):\n",
        " \n",
        "    test_x = yelp_test.text.values      \n",
        "    test_y = yelp_test.label.values\n",
        "  \n",
        "\n",
        "    test_labels = torch.tensor(test_y)\n",
        "\n",
        "    test_inputs, test_masks = preprocessing_for_labse(test_x)      #Preprocess the test instance \n",
        "\n",
        "    #Prepare testdataloader that will be used by the trained model\n",
        "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "  \n",
        "\n",
        "    #Predict the probabilites\n",
        "    probs = labse_predict(labse_classifier, test_dataloader)\n",
        "    preds = probs[:, 1]\n",
        "\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)     # if probability prediction is >=0.5 then it's class 1, and 0 otherwise \n",
        "\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "    return accuracy \n",
        "  \n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbhZp1q-YwW"
      },
      "source": [
        "Now that we have trained a LabSe classifier, which is fine-tuned on English sentences for the task of sentiment prediction, we can evaluate it. Not only will we evaluate its performance on an English test set, we will also test out several other languages (Dutch, French and Italian)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ywl7xoMMAMr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43af94a-9088-450d-d564-df3cb6c37838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy English: 46.50%\n",
            "Accuracy Dutch: 52.00%\n",
            "Accuracy French: 48.50%\n",
            "Accuracy Italian: 46.50%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "yelp_test_nl = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/nyelp_test_nl.csv\", encoding='latin-1')\n",
        "yelp_test_fr = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/nyelp_test_fr.csv\", encoding='latin-1')\n",
        "yelp_test_en = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/yelp_test.csv\", encoding='latin-1')\n",
        "yelp_test_it = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/nyelp_test_it.csv\", encoding='latin-1')\n",
        "\n",
        "nl_accuracy = accuracy_function(yelp_test_nl)\n",
        "fr_accuracy = accuracy_function(yelp_test_fr)\n",
        "en_accuracy = accuracy_function(yelp_test_en)\n",
        "it_accuracy = accuracy_function(yelp_test_it)\n",
        "\n",
        "print(f'Accuracy English: {en_accuracy*100:.2f}%')\n",
        "print(f'Accuracy Dutch: {nl_accuracy*100:.2f}%')\n",
        "print(f'Accuracy French: {fr_accuracy*100:.2f}%')\n",
        "print(f'Accuracy Italian: {it_accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvscZMK_AS4R"
      },
      "source": [
        "### Question-4\n",
        "\n",
        "Why would the model work on other languages than the one it was fine-tuned for (English)? Describe the pre-training strategy that leads to this 'language-agnostic' property of the LabSe model. You can consult the linked [blog post from the creators of the LabSe model](https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html) and other online sources to solve this question (please list the ones you used). \n",
        "\n",
        "-  LaBSE works with other languages than the ones it was fine-tuned with beacuse it is trained on a large amount of monoloingual sentences and bilingual sentence pairs. More precisely, the model uses two parallel encoders to encode two sequences and obtain their compatibility score. This strategy encourages the model to learn language-agnostic representations that generalize well to many different languages.\n",
        "https://www.youtube.com/watch?v=7tAWk_Coj-s&ab_channel=Rasa\n",
        "https://towardsdatascience.com/labse-language-agnostic-bert-sentence-embedding-by-google-ai-531f677d775f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpZs_939HsO3"
      },
      "source": [
        "# **Section 4: Fine-tuning T5 For Seq-to-Seq Task**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_KGxr0PClDE"
      },
      "source": [
        "So far, we have focused only on *classifiers* built on the top of Transformers. In this last exercise, we'll use a pretrained *sequence-to-sequence* transformer model to generate a summary for a given news article. Instead of outputting a probability distribution over classes (as is the case for classification), this model will take a text as an input, and output another text (hence, sequence-to-sequence). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vtz2F3wFH2A_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a217e3-e4a4-4f06-9fc4-992e96bfd8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.95)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install Sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "otAGkM0qH2FZ"
      },
      "outputs": [],
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9wcZQe0uH2IO"
      },
      "outputs": [],
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Rab6ghAcH-yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "79cde016-d56e-423b-8703-905aff51864c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  The Administration of Union Territory Daman an...   \n",
              "1  Malaika Arora slammed an Instagram user who tr...   \n",
              "2  The Indira Gandhi Institute of Medical Science...   \n",
              "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
              "4  Hotels in Maharashtra will train their staff t...   \n",
              "\n",
              "                                               ctext  \n",
              "0  The Daman and Diu administration on Wednesday ...  \n",
              "1  From her special numbers to TV?appearances, Bo...  \n",
              "2  The Indira Gandhi Institute of Medical Science...  \n",
              "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
              "4  Hotels in Mumbai and other Indian cities are t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-991bdb39-1d88-4b22-8f85-245f18c04009\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-991bdb39-1d88-4b22-8f85-245f18c04009')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-991bdb39-1d88-4b22-8f85-245f18c04009 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-991bdb39-1d88-4b22-8f85-245f18c04009');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/semerekiros/ML_NLP/main/news_summary_small.csv\", encoding='latin-1')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl9pynN1IQre"
      },
      "source": [
        "In the previous two exercises, we wrote our own preprocessing functions before creating our dataloaders. Here we'll directly use the `Dataset` module provided by `PyTorch`. It defines both how text is pre-processed and stores the instances with their corresponding labels. A `Dataloader` method then wraps an iterable around the `Dataset` in order to enable easy access to the samples before sending them to the neural network. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0LyHUINbH-1W"
      },
      "outputs": [],
      "source": [
        "class SummaryDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, source_len, summary_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = df\n",
        "        self.source_len = source_len\n",
        "        self.summary_len = summary_len\n",
        "        self.summarys = self.data.text\n",
        "        self.articles = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.summarys)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        article = str(self.articles[index])\n",
        "        article = ' '.join(article.split())\n",
        "\n",
        "        summary = str(self.summarys[index])\n",
        "        summary = ' '.join(summary.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([article], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([summary], max_length= self.summary_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmsLK1DEJdvz"
      },
      "source": [
        "As opposed to the previous exercises, we won't add any layers on top of the pre-trained transformer. This is because the pre-trained transformer we will use is already a sequence-to-sequence model, as is the task of providing a summary for a news article. \n",
        "\n",
        "We now immediately advance to defining the training loop. Note that the model's forward function (which we will load in later) takes the following arguments as an input: \n",
        "- the input sequence IDs\n",
        "- the attention mask\n",
        "- the decoder input IDs\n",
        "- the labels \n",
        "\n",
        "For more information about these arguments, please refer to [T5Model](https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5Model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "cFiQFmq_JcfS"
      },
      "outputs": [],
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "\n",
        "    #Freeze the encoder part of the t5, to limit required computational resources\n",
        "    for par in model.get_encoder().parameters():    \n",
        "        par.requires_grad = False\n",
        "  \n",
        "    model.train()\n",
        "    for _, data in enumerate(loader,0):\n",
        "        y = data['target_ids'].to(device, dtype=torch.long)\n",
        "        y_ids = y[:,:-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels [y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype=torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype=torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        if _%10 == 0:\n",
        "            print(f'Training Loss: {loss.item()}')\n",
        "        if _%500==0:\n",
        "            print(f'Epoch:{epoch}, Loss: {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnh0OjE7FHkB"
      },
      "source": [
        "The following function validates the performance of the model. It asks the model to generate an output sequence, based on a given input sequence. In our case, the input sequence will be a news article, and the output sequence will be its summary. To evaluate the model, we will calculate the BLEU-score between the predicted summary and the target summary. We will do this for all the news articles in our summary validation set, while training on the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "IZkKlP04Vy6t"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype=torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype =torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype =torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask,\n",
        "                max_length = 150,\n",
        "                num_beams=2,\n",
        "                repetition_penalty = 2.5,\n",
        "                length_penalty=1.0,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "\n",
        "            if _%10 == 0:\n",
        "                print(f'Completed {_}')\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "\n",
        "    return predictions, actuals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "q8BKI3PJFZk1"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(predictions, actuals):\n",
        "    predictions = [prediction.split(\" \") for prediction in predictions]\n",
        "    actuals = [[actual.split(\" \")] for actual in actuals]\n",
        "\n",
        "    score = bleu_score(predictions, actuals)\n",
        "\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBR6RzKeKDUD"
      },
      "source": [
        "Now, we load in the `Dataset` class as defined before and prepare the train and validation `Dataloader`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hhe95gTbKHCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a39243c-3463-4d6e-b579-b2c2cbffb631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (1000, 2)\n",
            "TRAIN Dataset: (800, 2)\n",
            "VAL Dataset: (200, 2)\n"
          ]
        }
      ],
      "source": [
        "model_config={\n",
        "    \"MODEL\":\"t5-base\",             # model_type: t5-base/t5-large\n",
        "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
        "    \"VALID_BATCH_SIZE\":20,          # validation batch size\n",
        "    \"TRAIN_EPOCHS\":2,              # number of training epochs\n",
        "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
        "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
        "    \"MAX_LEN\":512,  # max length of source text\n",
        "    \"SUMMARY_LEN\":150,   # max length of target text\n",
        "    \"SEED\": 42                     # set seed for reproducibility \n",
        "}\n",
        "\n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(model_config[\"SEED\"]) # pytorch random seed\n",
        "np.random.seed(model_config[\"SEED\"]) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "mytokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "df.ctext = 'summarize: ' + df.ctext   #pre-append each text with 'summarize' prompt\n",
        "\n",
        "\n",
        "# Creation of Dataset and Dataloader\n",
        "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state = model_config[\"SEED\"])\n",
        "val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"VAL Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = SummaryDataset(train_dataset, mytokenizer, model_config[\"MAX_LEN\"], model_config[\"SUMMARY_LEN\"])\n",
        "val_set = SummaryDataset(val_dataset, mytokenizer, model_config[\"MAX_LEN\"], model_config[\"SUMMARY_LEN\"])\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': model_config[\"TRAIN_BATCH_SIZE\"],\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': model_config[\"VALID_BATCH_SIZE\"],\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLK2YntPPK2F"
      },
      "source": [
        "We now take the pre-trained T5 language generation model, and finetune it on our summary dataset to create the `T5 Summarizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "sKctdxE1ODtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7752d7-942d-43c1-8b18-8ce475bc33bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n",
            "Training Loss: 6.1493144035339355\n",
            "Epoch:0, Loss: 6.1493144035339355\n",
            "Training Loss: 2.4344069957733154\n",
            "Training Loss: 2.351414203643799\n",
            "Training Loss: 1.8651801347732544\n",
            "Training Loss: 2.1591875553131104\n",
            "Training Loss: 2.250520944595337\n",
            "Training Loss: 1.9304931163787842\n",
            "Training Loss: 2.1510298252105713\n",
            "Training Loss: 1.6705858707427979\n",
            "Training Loss: 1.9244059324264526\n",
            "Training Loss: 1.7637704610824585\n",
            "Epoch:1, Loss: 1.7637704610824585\n",
            "Training Loss: 1.5756059885025024\n",
            "Training Loss: 1.8394076824188232\n",
            "Training Loss: 1.629102110862732\n",
            "Training Loss: 1.4356831312179565\n",
            "Training Loss: 1.9609870910644531\n",
            "Training Loss: 1.8042199611663818\n",
            "Training Loss: 1.8361130952835083\n",
            "Training Loss: 1.8112372159957886\n",
            "Training Loss: 1.528156042098999\n"
          ]
        }
      ],
      "source": [
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_config[\"LEARNING_RATE\"])\n",
        "\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(model_config[\"TRAIN_EPOCHS\"]):\n",
        "    train(epoch, mytokenizer, model, device, training_loader, optimizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrp1c8tuHAHO"
      },
      "source": [
        "Now, let's evaluate the performance of our summarizer in terms of the BLEU score metric. We can use the `validate` and `calculate_bleu` functions we defined earlier. You can ignore the warnings below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RifGtOqnbkNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc1f3d1-bca6-4c51-94d7-288b68e11c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 0\n",
            "0.11014135872578089\n"
          ]
        }
      ],
      "source": [
        "predictions, actuals = validate(1, mytokenizer, model, device, val_loader)   #Use the model to get predictions\n",
        "score = calculate_bleu(predictions, actuals)           #Calculate the bleu score between the predictions and the ground truth summaries\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CLc-gjeyVr"
      },
      "source": [
        "# Let's test it!\n",
        "\n",
        "We will now have a look at the news article summaries our model comes up with. We take the first instance in our validation set and ask our model to generate a summary. To do this, we'll use the `generate` function. As an input, we provide the same prompt as was used during finetuning of the model (`summarize: <news article>`). Thanks to the training process, the language generation model will know how to generate a summary of the article. \n",
        "\n",
        "If you are looking for a good read on the underlying techniques for text generation (greedy search, beam search, ...) and some examples of how to use the `generate` method, please have a look at this [blog post from huggingface](https://huggingface.co/blog/how-to-generate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "eytHRK1HansD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee366f25-96ef-4a2c-e2f9-5e73418adfcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Hotels in Mumbai and other Indian cities are to train their staff to spot signs of sex trafficking such as frequent requests for bed linen changes or a \"Do not disturb\" sign left on the door for days on end. The group behind the initiative is also developing a mobile phone app - Rescue Me - which hotel staff can use to alert local police and senior anti-trafficking officers if they see suspicious behavior. \"Hotels are breeding grounds for human trade,\" said Sanee Awsarmmel, chairman of the alumni group of Maharashtra State Institute of Hotel Management and Catering Technology. \"(We) have hospitality professionals working in hotels across the country. We are committed to this cause.\"The initiative, spearheaded by the alumni group and backed by the Maharashtra state government, comes amid growing international recognition that hotels have a key role to play in fighting modern day slavery. MAHARASHTRA MAJOR DESTINATION FOR TRAFFICKED GIRLS Maharashtra, of which Mumbai is the capital, is a major destination for trafficked girls who are lured from poor states and nearby countries on the promise of jobs, but then sold into the sex trade or domestic servitude. With rising property prices, some traditional red light districts like those in Mumbai have started to disappear pushing the sex trade underground into private lodges and hotels, which makes it hard for police to monitor.Awsarmmel said hotels would be told about 50 signs that staff needed to watch out for.These include requests for rooms with a view of the car park which are favored by traffickers as they allow them to vet clients for signs of trouble and check out their cars to gauge how much to charge.Awsarmmel said hotel staff often noticed strange behavior such as a girl's reticence during the check-in process or her dependence on the person accompanying her to answer questions and provide her proof of identity.But in most cases, staff ignore these signs or have no idea what to do, he told the Thomson Reuters Foundation.RESCUE ME APP The Rescue Me app - to be launched in a couple of months - will have a text feature where hotel staff can fill in details including room numbers to send an alert to police.Human trafficking is the world's fastest growing criminal enterprise worth an estimated $150 billion a year, according to the International Labor Organization, which says nearly 21 million people globally are victims of forced labor and trafficking.Last year, major hotel groups, including the Hilton and Shiva Hotels, pledged to examine their supply chains for forced labor, and train staff how to spot and report signs of trafficking.Earlier this year, Mexico City also launched an initiative to train hotel staff about trafficking.Vijaya Rahatkar, chairwoman of the Maharashtra State Women's Commission, said the initiative would have an impact beyond the state as the alumni group had contact with about a million small hotels across India.The group is also developing a training module on trafficking for hotel staff and hospitality students which could be used across the country.ALSO READFYI | Legal revenge: Child sex trafficking survivors get 'School of Justice' to fight their own battlesMumbai: Woman DJ arrested in high-profile sex racket case\n"
          ]
        }
      ],
      "source": [
        "test_sent = val_dataset.ctext.values[1]\n",
        "print(test_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0b8V62gdWw8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567a73af-c155-4666-9eca-cc44f2670b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Decoding strategy: Beam search, \n",
            " Generated summary:  hotels in Mumbai and other Indian cities are to train staff to spot signs of sex trafficking such as frequent requests for bed linen changes or a \"Do not disturb\" sign left on the door for days on end. The initiative comes amid growing international recognition that hotels have a key role to play in fighting modern day slavery.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "test_tokenized = mytokenizer.encode_plus(test_sent, max_length = model_config[\"MAX_LEN\"], pad_to_max_length=True, return_tensors=\"pt\")\n",
        "\n",
        "test_input_ids  = test_tokenized[\"input_ids\"]\n",
        "test_attention_mask = test_tokenized[\"attention_mask\"]\n",
        "\n",
        "test_input_ids = test_input_ids.to(device, dtype=torch.long)\n",
        "test_attention_mask = test_attention_mask.to(device, dtype=torch.long)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "beam_outputs = model.generate(\n",
        "    input_ids = test_input_ids,\n",
        "    attention_mask = test_attention_mask,\n",
        "    max_length = 150,\n",
        "    num_beams=2,\n",
        "    repetition_penalty = 2.5,\n",
        "    length_penalty=1.0,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "for beam_output in beam_outputs:\n",
        "    predicted_summary = mytokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    print(f' Decoding strategy: Beam search, \\n Generated summary:  {predicted_summary}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS0IigLaZgt5"
      },
      "source": [
        "Beam search was used to generate the previous summary. As is mentioned in the [blog post](https://huggingface.co/blog/how-to-generate) many other decoding strategies can be used to generate output sequence, given an input sequence. Here, we ask you to use nucleus sampling, also called `top-p sampling`. Have a look at how we implemented the beam-search decoding strategy in the code above (`beam_outputs = model.generate(...)`), and add some arguments which ensure that top-p sampling is used instead of beam search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "WKJtqd1PZeJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a48080-8f8c-49c6-fae3-2251b02c2075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Decoding strategy: Nucleus sampling, \n",
            " Generated summary:  hotel staff will be trained to spot signs of sex trafficking, including frequent requests for bed linen changes and a \"Do not disturb\" sign left on the door for days on end. The initiative comes amid growing international recognition that hotels have a key role to play in fighting modern day slavery.\n",
            " Decoding strategy: Nucleus sampling, \n",
            " Generated summary:  hotels in Mumbai and other Indian cities are to train staff to spot signs of sex trafficking such as frequent requests for bed linen changes or a \"Do not disturb\" sign left on the door for days on end. The initiative is also developing a mobile phone app which staff can use to alert local police and senior anti-trafficking officers if they see suspicious behavior.\n"
          ]
        }
      ],
      "source": [
        "# Write the decoding strategy with nucleus sampling \n",
        "#  \n",
        "# sample_outputs = model.generate (\n",
        "#    ...\n",
        "#    specify some additional arguments to implement top-p sampling with a probability of 0.88\n",
        "#  )\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids = test_input_ids,\n",
        "    attention_mask = test_attention_mask,\n",
        "    max_length = 150,\n",
        "    num_beams=2,\n",
        "    repetition_penalty = 2.5,\n",
        "    length_penalty=1.0,\n",
        "    early_stopping=True,\n",
        "    ############### for student ###################\n",
        "    top_k=100,\n",
        "    top_p=0.88,\n",
        "    num_return_sequences=2,\n",
        "    do_sample=True\n",
        "    ##############################################\n",
        ")\n",
        "\n",
        "\n",
        "for sample_output in sample_outputs:\n",
        "    predicted_summary =  mytokenizer.decode(sample_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    print(f' Decoding strategy: Nucleus sampling, \\n Generated summary:  {predicted_summary}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u92QVSRRo_gQ"
      },
      "source": [
        "### Acknowledgment\n",
        "\n",
        "If you received help or feedback from fellow students, please acknowledge that here. We count on your academic honesty:\n",
        "\n",
        "**<font color=blue><<< LIST POTENTIAL COLLABORATORS HERE >>></font>**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "A_fCN7FpeaCC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66842705b10545f78ad9a60ec90ade56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f0b65c239ec4e1482a4cf0e6a026b15",
              "IPY_MODEL_7d86ce93ec314c4791c62909809a1989",
              "IPY_MODEL_069e85ffbd734aa39090084116171517"
            ],
            "layout": "IPY_MODEL_68bfd3c452f74f11838a2a2339281d1a"
          }
        },
        "5f0b65c239ec4e1482a4cf0e6a026b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8baf202746624c118986a31cdd943350",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe4ef25fafe4b2288896b5c84dd3e72",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "7d86ce93ec314c4791c62909809a1989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c51f944ae674b498a29fce38ea35cb3",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d46cab9f02e42bbbc5b62954d081984",
            "value": 791656
          }
        },
        "069e85ffbd734aa39090084116171517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee24497771814693ad887fdb69da930a",
            "placeholder": "​",
            "style": "IPY_MODEL_7b5bc7627d1e4489bbc998fca55deb33",
            "value": " 792k/792k [00:00&lt;00:00, 942kB/s]"
          }
        },
        "68bfd3c452f74f11838a2a2339281d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baf202746624c118986a31cdd943350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe4ef25fafe4b2288896b5c84dd3e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c51f944ae674b498a29fce38ea35cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d46cab9f02e42bbbc5b62954d081984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee24497771814693ad887fdb69da930a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5bc7627d1e4489bbc998fca55deb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b161767a1ae43ce968f29179dae2fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa70a336cd345bdbcab2cc126ca86fd",
              "IPY_MODEL_627d2a3b2364424f8dc992f0f1348962",
              "IPY_MODEL_05e689d8c4a146428780d23a353c6248"
            ],
            "layout": "IPY_MODEL_7cb920c2e0c14a5582ba51734737aa3f"
          }
        },
        "2aa70a336cd345bdbcab2cc126ca86fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb259e7cd20d4a3890b1ec82c8f777b2",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa6068b45df451285c28a083c812601",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "627d2a3b2364424f8dc992f0f1348962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3061706cc1db4b73887e990f672e8d72",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9ef3405d3de48e6af2a9b3ca8f17fed",
            "value": 1208
          }
        },
        "05e689d8c4a146428780d23a353c6248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8043e9b9694a40b5941745a879f44ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_211babb11e0b4c72a81956618b0d9f64",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 92.2kB/s]"
          }
        },
        "7cb920c2e0c14a5582ba51734737aa3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb259e7cd20d4a3890b1ec82c8f777b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa6068b45df451285c28a083c812601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3061706cc1db4b73887e990f672e8d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ef3405d3de48e6af2a9b3ca8f17fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8043e9b9694a40b5941745a879f44ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211babb11e0b4c72a81956618b0d9f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0771bf61d4e4881960670c82c32385c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b940d7a2e7041289ec1565335992a27",
              "IPY_MODEL_28565eae5daa45628fe5ebe1d2b478c8",
              "IPY_MODEL_9e125ebfa8ad4b0d9d0e69303ae71076"
            ],
            "layout": "IPY_MODEL_d5be56643e264a80976ea3de571490ff"
          }
        },
        "4b940d7a2e7041289ec1565335992a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b1ddd78bd04447a75ea3288abcbf5c",
            "placeholder": "​",
            "style": "IPY_MODEL_04e278470fc34c65808e1cdd08816528",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "28565eae5daa45628fe5ebe1d2b478c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06e47fb615e4a349a95982a5d56ecd4",
            "max": 891691430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c335db65d724bc7898c5a5492ea96d4",
            "value": 891691430
          }
        },
        "9e125ebfa8ad4b0d9d0e69303ae71076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5ae09dad72464382c98ab3e878c396",
            "placeholder": "​",
            "style": "IPY_MODEL_7074c86a0c914ddeb930d52749b139dd",
            "value": " 892M/892M [00:03&lt;00:00, 249MB/s]"
          }
        },
        "d5be56643e264a80976ea3de571490ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b1ddd78bd04447a75ea3288abcbf5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e278470fc34c65808e1cdd08816528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06e47fb615e4a349a95982a5d56ecd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c335db65d724bc7898c5a5492ea96d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b5ae09dad72464382c98ab3e878c396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7074c86a0c914ddeb930d52749b139dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b8bd07a5f64a7ea893e613357d5b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e544e4e0ce24175aff5f8b1448de0ca",
              "IPY_MODEL_97276fc19a9b46cfbfa4e1795324f4e3",
              "IPY_MODEL_ee34145d4cc947059e999f51c716ce38"
            ],
            "layout": "IPY_MODEL_3b911f20ffca4d65ba51617c4ef669bf"
          }
        },
        "8e544e4e0ce24175aff5f8b1448de0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d455b06b4d424f179ad9fa5c855591c1",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb49f311fe64267b5d1e476282a2ffb",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "97276fc19a9b46cfbfa4e1795324f4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70abf94ffedf4570b43807bdcd8cee17",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00e1419afa8f48da9a324f1ad63f5b8c",
            "value": 147
          }
        },
        "ee34145d4cc947059e999f51c716ce38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d077f93d68495ca65d02304e94b845",
            "placeholder": "​",
            "style": "IPY_MODEL_cc791fb65e394502bbde9b47e0042512",
            "value": " 147/147 [00:00&lt;00:00, 3.07kB/s]"
          }
        },
        "3b911f20ffca4d65ba51617c4ef669bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d455b06b4d424f179ad9fa5c855591c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb49f311fe64267b5d1e476282a2ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70abf94ffedf4570b43807bdcd8cee17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e1419afa8f48da9a324f1ad63f5b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71d077f93d68495ca65d02304e94b845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc791fb65e394502bbde9b47e0042512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47e90254bfb4fcf99b616b104deaa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93b10ec0d7634a8eaacaa638e4f0fea6",
              "IPY_MODEL_db649c782dba4cb09dadfccf6e42c183",
              "IPY_MODEL_0ce253b7c74845e5b0129d9ea35d9633"
            ],
            "layout": "IPY_MODEL_60ae4e20f442483e92c7e5ddf6184641"
          }
        },
        "93b10ec0d7634a8eaacaa638e4f0fea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c33b30398c417a9b6d3556818c8f86",
            "placeholder": "​",
            "style": "IPY_MODEL_eb548d5ef38640c88113972a75d51c78",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "db649c782dba4cb09dadfccf6e42c183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3337eb94450049a4bf1ace6c3f3f3f7e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b066a0c084b4ad8aee40b379495a512",
            "value": 231508
          }
        },
        "0ce253b7c74845e5b0129d9ea35d9633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91419961eb72467190db3f84fcb8c912",
            "placeholder": "​",
            "style": "IPY_MODEL_e5507ebaa5c24b8fad28650954d4b45d",
            "value": " 232k/232k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "60ae4e20f442483e92c7e5ddf6184641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c33b30398c417a9b6d3556818c8f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb548d5ef38640c88113972a75d51c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3337eb94450049a4bf1ace6c3f3f3f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b066a0c084b4ad8aee40b379495a512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91419961eb72467190db3f84fcb8c912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5507ebaa5c24b8fad28650954d4b45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b85d78813084afe9c0ffbd2c0fb986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd02ab6c30d940bb94b9fe1234347a22",
              "IPY_MODEL_47fa5bbf8b4f4544990ec69309d3ca4f",
              "IPY_MODEL_f837c095d11f4533bcae98a7590084f6"
            ],
            "layout": "IPY_MODEL_6990f45e177444f683f763c25dc66fdf"
          }
        },
        "cd02ab6c30d940bb94b9fe1234347a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a924ff5ee6ff4af0b331dffe41f5ecdd",
            "placeholder": "​",
            "style": "IPY_MODEL_71a5c3e333604e59a5876a9365aed934",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "47fa5bbf8b4f4544990ec69309d3ca4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2652dbcfda4340b7aaa307907690f9",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff9cc159c6014b08940752c291cec3af",
            "value": 28
          }
        },
        "f837c095d11f4533bcae98a7590084f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2265560be374c5b80bc01e134eec872",
            "placeholder": "​",
            "style": "IPY_MODEL_d4a0b97f2cb24e67b9d7eaaac71da6d6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.56kB/s]"
          }
        },
        "6990f45e177444f683f763c25dc66fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a924ff5ee6ff4af0b331dffe41f5ecdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a5c3e333604e59a5876a9365aed934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2652dbcfda4340b7aaa307907690f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9cc159c6014b08940752c291cec3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2265560be374c5b80bc01e134eec872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a0b97f2cb24e67b9d7eaaac71da6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42247fa19bdd4b7ebb426206f3ef9fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49f4c35634144433a4298ddce2a42cfa",
              "IPY_MODEL_d0f97553ff2f44bea4ffde20151dfff2",
              "IPY_MODEL_aeadf58529e546ebb7c7493ffb056205"
            ],
            "layout": "IPY_MODEL_a5c619a73bfd4418b68caa31d8fda16a"
          }
        },
        "49f4c35634144433a4298ddce2a42cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bbf0d2448874e12badb5d48f5d6a22a",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a90a4f339d4bc5bcecfbdbf54a87c1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d0f97553ff2f44bea4ffde20151dfff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa1431f51d84130816cfa01ef985f31",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18b752e6446a4e19b70670d9c479799b",
            "value": 483
          }
        },
        "aeadf58529e546ebb7c7493ffb056205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1934ed6e37a418f99fd30be92356927",
            "placeholder": "​",
            "style": "IPY_MODEL_5799a1407eb24dd0a9e5079720f61763",
            "value": " 483/483 [00:00&lt;00:00, 41.3kB/s]"
          }
        },
        "a5c619a73bfd4418b68caa31d8fda16a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bbf0d2448874e12badb5d48f5d6a22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a90a4f339d4bc5bcecfbdbf54a87c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa1431f51d84130816cfa01ef985f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b752e6446a4e19b70670d9c479799b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1934ed6e37a418f99fd30be92356927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5799a1407eb24dd0a9e5079720f61763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f819e9b203c945e185dfbf976659542c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_705b1c4a28434000be5e11f1a3dd152f",
              "IPY_MODEL_fec04461235c4f28843ba8a48c67c620",
              "IPY_MODEL_acabaeded6024ec0bfa3fb2870fa5d2e"
            ],
            "layout": "IPY_MODEL_b420e1ee320148908ed7f3bbfbe2615c"
          }
        },
        "705b1c4a28434000be5e11f1a3dd152f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46e59d027064baaab21d491c165bafb",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf547bbe7284b3c99ab9c6dc42f65b9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "fec04461235c4f28843ba8a48c67c620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef1e8b057764a30b2d501d188bc1e64",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c251ecc9a84c619cbe6ac0287a874a",
            "value": 267967963
          }
        },
        "acabaeded6024ec0bfa3fb2870fa5d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac022fc8d4364427aac6c513f4b171b0",
            "placeholder": "​",
            "style": "IPY_MODEL_c7cceb6e830f46c38c5db4758808e71b",
            "value": " 268M/268M [00:01&lt;00:00, 279MB/s]"
          }
        },
        "b420e1ee320148908ed7f3bbfbe2615c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46e59d027064baaab21d491c165bafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf547bbe7284b3c99ab9c6dc42f65b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef1e8b057764a30b2d501d188bc1e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c251ecc9a84c619cbe6ac0287a874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac022fc8d4364427aac6c513f4b171b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cceb6e830f46c38c5db4758808e71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8343c7815d6d4564b0128beed266448c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90bd4cc455f24d57ba06777fe2cec727",
              "IPY_MODEL_6688338eb9f642eeb7174f949849509d",
              "IPY_MODEL_1dc7eb78e9414353813f1055eccf995b"
            ],
            "layout": "IPY_MODEL_8e475bf5c0b04c7fb74ac8ec78c6e941"
          }
        },
        "90bd4cc455f24d57ba06777fe2cec727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2b564592834ff09ff9d937951ace50",
            "placeholder": "​",
            "style": "IPY_MODEL_4b299bb4368f4dc7b930c74f2fbe4f0d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6688338eb9f642eeb7174f949849509d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c940befa33ef4c17a6471b2a8eba318c",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f52cb75ca8b42a496e09deb2891dfee",
            "value": 62
          }
        },
        "1dc7eb78e9414353813f1055eccf995b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d011d98003884782ad9e59cde4b01598",
            "placeholder": "​",
            "style": "IPY_MODEL_a38a109e0c3c4e188c2c97606def975d",
            "value": " 62.0/62.0 [00:00&lt;00:00, 2.63kB/s]"
          }
        },
        "8e475bf5c0b04c7fb74ac8ec78c6e941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2b564592834ff09ff9d937951ace50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b299bb4368f4dc7b930c74f2fbe4f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c940befa33ef4c17a6471b2a8eba318c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f52cb75ca8b42a496e09deb2891dfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d011d98003884782ad9e59cde4b01598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a38a109e0c3c4e188c2c97606def975d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e92413bde84489b97409cbb841cef3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4eb2b13d4314c8c94b21a819ac0aa7f",
              "IPY_MODEL_bcf2d4e95fd244e6b6589aa39145e7dc",
              "IPY_MODEL_05eaa32c55bd42c5924a447bdd4f88fd"
            ],
            "layout": "IPY_MODEL_aba49d548c204333be1022f7a4fdd6a5"
          }
        },
        "a4eb2b13d4314c8c94b21a819ac0aa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1aff73f1d242c6b1e7f54128d7227a",
            "placeholder": "​",
            "style": "IPY_MODEL_833c9530087c43939646129c80a5cdf5",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "bcf2d4e95fd244e6b6589aa39145e7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd79ea5104f74a97b831ab501b58f850",
            "max": 472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4832d9c702d34e118fb20f0bff64a77a",
            "value": 472
          }
        },
        "05eaa32c55bd42c5924a447bdd4f88fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_352fdffd3304402e9a76242a2c7fd898",
            "placeholder": "​",
            "style": "IPY_MODEL_43f00a8f79b54f0cb3ac3711add45ef4",
            "value": " 472/472 [00:00&lt;00:00, 38.2kB/s]"
          }
        },
        "aba49d548c204333be1022f7a4fdd6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1aff73f1d242c6b1e7f54128d7227a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833c9530087c43939646129c80a5cdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd79ea5104f74a97b831ab501b58f850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4832d9c702d34e118fb20f0bff64a77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "352fdffd3304402e9a76242a2c7fd898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f00a8f79b54f0cb3ac3711add45ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae4b4b0fb5942999db3b1e9144d6df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9808bd828684cd69a0a5328a2634c03",
              "IPY_MODEL_a2fb7d665f22412e9790247ecc1ecee0",
              "IPY_MODEL_12e1f17dedaf4658bb1a473b2b34447b"
            ],
            "layout": "IPY_MODEL_a7f9053d095e4c7e8f40e973fab1a3b5"
          }
        },
        "b9808bd828684cd69a0a5328a2634c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29395c6b54804ecaad630fa1c64ae646",
            "placeholder": "​",
            "style": "IPY_MODEL_3d188f4ec23743569ffde3291f6353c6",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "a2fb7d665f22412e9790247ecc1ecee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484109424b304376a1062be6a03c42a7",
            "max": 5220781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8b02cd6fd804584a0329721d93b68bd",
            "value": 5220781
          }
        },
        "12e1f17dedaf4658bb1a473b2b34447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53eb1c4224b8413f95cea417195271b3",
            "placeholder": "​",
            "style": "IPY_MODEL_4ca13dd169f241229f11976c593ca1aa",
            "value": " 5.22M/5.22M [00:01&lt;00:00, 3.52MB/s]"
          }
        },
        "a7f9053d095e4c7e8f40e973fab1a3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29395c6b54804ecaad630fa1c64ae646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d188f4ec23743569ffde3291f6353c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484109424b304376a1062be6a03c42a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b02cd6fd804584a0329721d93b68bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53eb1c4224b8413f95cea417195271b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca13dd169f241229f11976c593ca1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf08fe5c9cae4ee0859ebebd3e70bd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55235387620b4757a6fb11ed96409223",
              "IPY_MODEL_c3bdc2253a594b728158f99eb6e050f6",
              "IPY_MODEL_e67475d019b34eb486d8a4d10b727e73"
            ],
            "layout": "IPY_MODEL_026c2ccc64524cd9a945d0423023ccaf"
          }
        },
        "55235387620b4757a6fb11ed96409223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683c101ae50c4268a7628a18d02bc527",
            "placeholder": "​",
            "style": "IPY_MODEL_68746dda3a0640e1965616f3d0169842",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "c3bdc2253a594b728158f99eb6e050f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c5289d22e214f79bc5eaaa5c43a22ee",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efe1cc99d10f4167bfe4afa1ea5cb31c",
            "value": 112
          }
        },
        "e67475d019b34eb486d8a4d10b727e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd687f3c2fa4f458942fa647917575d",
            "placeholder": "​",
            "style": "IPY_MODEL_c495ae7f6dde44cc857dc274d1793624",
            "value": " 112/112 [00:00&lt;00:00, 8.40kB/s]"
          }
        },
        "026c2ccc64524cd9a945d0423023ccaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683c101ae50c4268a7628a18d02bc527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68746dda3a0640e1965616f3d0169842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c5289d22e214f79bc5eaaa5c43a22ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe1cc99d10f4167bfe4afa1ea5cb31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd687f3c2fa4f458942fa647917575d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c495ae7f6dde44cc857dc274d1793624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}